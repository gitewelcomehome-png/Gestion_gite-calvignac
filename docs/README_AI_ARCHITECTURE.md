# ğŸ¤– Assistant IA - Architecture CentralisÃ©e

## ğŸ¯ Vue d'ensemble

L'Assistant IA utilise une **architecture centralisÃ©e** :
- âœ… **Votre clÃ© API** OpenAI est stockÃ©e cÃ´tÃ© serveur (Vercel)
- âœ… **Vous payez** pour tous les utilisateurs
- âœ… **Aucune configuration** nÃ©cessaire pour les utilisateurs
- âœ… **SÃ©curisÃ©** - La clÃ© n'est jamais exposÃ©e au frontend

---

## ğŸ“ Fichiers

### `/api/openai.js`
Fonction serverless Vercel qui :
- ReÃ§oit les demandes du frontend
- Appelle OpenAI avec votre clÃ© (stockÃ©e en env)
- Retourne le contenu gÃ©nÃ©rÃ©

### `/js/ai-assistant.js`
Module frontend qui :
- Affiche les boutons âœ¨ dans l'interface
- Collecte les mots-clÃ©s de l'utilisateur
- Appelle `/api/openai` (pas OpenAI directement)
- InsÃ¨re le contenu gÃ©nÃ©rÃ© dans les champs

### `/.env.example`
Template des variables d'environnement nÃ©cessaires.

### `/docs/CONFIGURATION_OPENAI_VERCEL.md`
Guide dÃ©taillÃ© de configuration pour le propriÃ©taire.

---

## ğŸš€ Configuration Rapide

### 1. Obtenir votre clÃ© OpenAI
```bash
# 1. Allez sur https://platform.openai.com/api-keys
# 2. CrÃ©ez une nouvelle clÃ© secrÃ¨te
# 3. Copiez-la (sk-proj-...)
```

### 2. Ajouter dans Vercel
```bash
# Via CLI
vercel env add OPENAI_API_KEY

# Ou via Dashboard Vercel:
# Settings â†’ Environment Variables â†’ Add
# Name: OPENAI_API_KEY
# Value: sk-proj-...
# Environments: Production + Preview + Development
```

### 3. RedÃ©ployer
```bash
vercel --prod
```

---

## ğŸ’° CoÃ»ts

- **ModÃ¨le** : GPT-4o-mini
- **Estimation** : ~0,15â‚¬ pour 1000 gÃ©nÃ©rations
- **Budget recommandÃ©** : 5-20â‚¬/mois selon usage

Surveillez : [platform.openai.com/usage](https://platform.openai.com/usage)

---

## ğŸ”’ SÃ©curitÃ©

### âœ… Architecture sÃ©curisÃ©e
- ClÃ© API stockÃ©e cÃ´tÃ© serveur (Vercel Environment Variables)
- Jamais exposÃ©e au frontend
- ChiffrÃ©e au repos
- Accessible uniquement par la fonction serverless

### ğŸ›¡ï¸ Protection recommandÃ©e
- DÃ©finir des limites de dÃ©penses sur OpenAI
- Monitorer les logs Vercel Functions
- Ajouter rate limiting si nÃ©cessaire
- Restreindre CORS en production (modifier `/api/openai.js`)

---

## ğŸ§ª Test Local

### 1. CrÃ©er `.env.local`
```bash
cp .env.example .env.local
# Ã‰diter .env.local et ajouter votre clÃ© OpenAI
```

### 2. Lancer Vercel Dev
```bash
vercel dev
```

### 3. Tester l'API
```bash
curl -X POST http://localhost:3000/api/openai \
  -H "Content-Type: application/json" \
  -d '{"prompt": "DÃ©cris une boÃ®te Ã  clÃ©s avec le code 1234", "maxTokens": 200}'
```

---

## ğŸ“Š Monitoring

### Logs Vercel
```
Dashboard Vercel â†’ Functions â†’ /api/openai
```

### Usage OpenAI
```
https://platform.openai.com/usage
```

### MÃ©triques Ã  surveiller
- Nombre d'appels/jour
- CoÃ»t moyen/appel
- Taux d'erreur
- Temps de rÃ©ponse

---

## ğŸ†˜ DÃ©pannage

### "API OpenAI non configurÃ©e"
â†’ Variable `OPENAI_API_KEY` manquante dans Vercel

### "Invalid API key"
â†’ ClÃ© incorrecte ou rÃ©voquÃ©e, gÃ©nÃ©rer une nouvelle

### Erreurs 429 (Rate limit)
â†’ Trop de requÃªtes, augmenter les limites OpenAI

### Erreurs 500
â†’ VÃ©rifier les logs dans Vercel Functions

---

## ğŸ“š Documentation ComplÃ¨te

Consultez [CONFIGURATION_OPENAI_VERCEL.md](./docs/CONFIGURATION_OPENAI_VERCEL.md) pour le guide dÃ©taillÃ©.
