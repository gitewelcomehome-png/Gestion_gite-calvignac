# ðŸ“Š GUIDE SCALABILITÃ‰ TECHNIQUE 0-100K USERS
## LiveOwnerUnit - Architecture & Optimisations

**Version :** 2.0  
**Date :** 14 fÃ©vrier 2026  
**Architecture :** Supabase PostgreSQL (AUCUNE REFONTE)  
**Cible MAX :** 100 000 utilisateurs

---

## ðŸŽ¯ PRINCIPE

**Votre architecture actuelle tient jusqu'Ã  100k users SANS REFONTE du code.**

PostgreSQL (Supabase) gÃ¨re des millions de rows. Exemples :
- Instagram au dÃ©but : PostgreSQL avec millions d'users
- Discourse (forums) : PostgreSQL, 100k+ users actifs
- GitLab : PostgreSQL, millions de repos/users

**Ce qu'il faut faire :** Optimiser progressivement + payer l'infra plus cher.

---

## ðŸ“‹ TABLEAU RÃ‰CAPITUL ATIF

| Palier | Users | Infra | CoÃ»t/mois | Actions | Temps |
|--------|-------|-------|-----------|---------|-------|
| **0** | 0-50 | Supabase Free | 0 â‚¬ | Aucune | 0h |
| **1** | 50-500 | Supabase Free | 0 â‚¬ | Indexes SQL | 30min |
| **2** | 500-2k | Supabase Pro | 25 â‚¬ | Pagination + RequÃªtes | 3h |
| **3** | 2k-10k | Supabase Team | 699 â‚¬ | Redis cache + CDN | 8h |
| **4** | 10k-30k | Supabase Team | 699 â‚¬ | Database tuning + Queue | 10h |
| **5** | 30k-100k | Enterprise | ~5k â‚¬ | Read replicas + Monitoring | 8h |

**Total dÃ©veloppement : ~30h Ã©talÃ©es sur croissance**  
**Total coÃ»ts 3 ans (si 100k users atteints) : ~200kâ‚¬** 

---

## ðŸŸ¢ PALIER 0 : 0-50 USERS

### Infrastructure
- Supabase Free : 500 MB, 500k API req/mois
- Vercel Free

### Actions
**AUCUNE.** L'infra actuelle suffit.

### MÃ©triques Ã  surveiller
- Storage Supabase < 100 MB
- API requests < 100k/mois

---

## ðŸŸ¡ PALIER 1 : 50-500 USERS

### Seuil d'action
- Storage > 100 MB **OU**
- Temps de chargement > 3s **OU**
- Pagination manuelle lourde

### âœ… TODO #1 : Indexes SQL critiques (30 min)

**Pourquoi :** AccÃ©lÃ¨re les requÃªtes de 100x-1000x.

```sql
-- Indexes pour requÃªtes frÃ©quentes
CREATE INDEX idx_reservations_user_dates 
  ON reservations(user_id, date_debut, date_fin);

CREATE INDEX idx_reservations_gite_dates 
  ON reservations(gite_id, date_debut, date_fin);

CREATE INDEX idx_activites_gite 
  ON activites(gite_id);

CREATE INDEX idx_menages_gite_date 
  ON menages(gite_id, date_menage);

-- Index pour recherche texte (nom client)
CREATE INDEX idx_reservations_client_nom 
  ON reservations USING gin(to_tsvector('french', nom_client));
```

**RÃ©sultat attendu :** Chargement rÃ©servations passe de 2-3s Ã  < 200ms.

---

## ðŸŸ  PALIER 2 : 500-2000 USERS

### Seuil d'action
- Supabase Free limits atteintes **OU**
- > 500k API req/mois **OU**
- Temps rÃ©ponse > 2s

### âœ… TODO #2 : Migration Supabase Pro (20 min)

**CoÃ»t :** 25 â‚¬/mois  
**Limites :** 8 GB storage, 2 GB bandwidth, 2B req/mois

Dans Supabase Dashboard :
1. Settings > Billing
2. Upgrade to Pro
3. Ajouter carte bancaire

### âœ… TODO #3 : Pagination cÃ´tÃ© serveur (2h)

**Dans `js/tab-reservations.js` :**

```javascript
const ITEMS_PER_PAGE = 50;
let currentPage = 1;

async function loadReservations(page = 1) {
  const from = (page - 1) * ITEMS_PER_PAGE;
  const to = from + ITEMS_PER_PAGE - 1;
  
  const { data, count, error } = await supabase
    .from('reservations')
    .select('*', { count: 'exact' })
    .eq('user_id', userId)
    .order('date_debut', { ascending: false })
    .range(from, to);
  
  if (error) throw error;
  
  renderReservations(data);
  renderPagination(page, Math.ceil(count / ITEMS_PER_PAGE));
}

function renderPagination(current, total) {
  const pagination = document.getElementById('pagination');
  pagination.innerHTML = `
    <button ${current === 1 ? 'disabled' : ''} 
      onclick="loadReservations(${current - 1})">PrÃ©cÃ©dent</button>
    <span>Page ${current} / ${total}</span>
    <button ${current === total ? 'disabled' : ''} 
      onclick="loadReservations(${current + 1})">Suivant</button>
  `;
}
```

**Appliquer Ã  :**
- tab-reservations.js
- tab-statistiques.js  
- tab-fiches-clients.js
- tab-menage.js

### âœ… TODO #4 : Optimiser requÃªtes N+1 (1h)

**ProblÃ¨me frÃ©quent :** Charger rÃ©servations puis faire 1 requÃªte par gÃ®te.

**Avant (lent) :**
```javascript
// Charge toutes les rÃ©servations
const reservations = await supabase.from('reservations').select('*');

// Pour CHAQUE rÃ©servation, charge le gÃ®te (N+1 queries)
for (const resa of reservations) {
  const gite = await supabase
    .from('gites')
    .select('*')
    .eq('id', resa.gite_id)
    .single();
  resa.giteNom = gite.nom;
}
```

**AprÃ¨s (rapide) :**
```javascript
// 1 seule requÃªte avec JOIN
const { data } = await supabase
  .from('reservations')
  .select(`
    *,
    gites (
      id,
      nom,
      adresse
    )
  `)
  .eq('user_id', userId);

// data[0].gites.nom directement disponible
```

**Appliquer partout oÃ¹ il y a des relations.**

---

## ðŸ”´ PALIER 3 : 2000-10 000 USERS

### Seuil d'action
- > 1M API req/mois **OU**
- Storage > 5 GB **OU**
- Temps rÃ©ponse > 1s sur pages liste

### âœ… TODO #5 : Migration Supabase Team (20 min)

**CoÃ»t :** 699 â‚¬/mois  
**Limites :** 100 GB storage, 250 GB bandwidth, database replicas

### âœ… TODO #6 : Redis cache Upstash (3h)

**Pourquoi :** Ã‰viter de recalculer les mÃªmes donnÃ©es (stats, taux occupation, etc.).

**1. CrÃ©er compte Upstash Redis (gratuit jusqu'Ã  10k req/jour)**

https://upstash.com â†’ Create Database (RÃ©gions Europe)

**2. Installer client :**

```html
<!-- Dans index.html -->
<script src="https://cdn.jsdelivr.net/npm/@upstash/redis@latest/dist/index.js"></script>
```

**3. Config dans `config.js` :**

```javascript
const redis = new Upstash.Redis({
  url: 'UPSTASH_REDIS_REST_URL',
  token: 'UPSTASH_REDIS_REST_TOKEN'
});
```

**4. Cacher statistiques (exemple `tab-statistiques.js`) :**

```javascript
async function loadStatistiques() {
  const cacheKey = `stats:${userId}:${new Date().toISOString().slice(0, 7)}`; // stats:USER:2026-02
  
  // Essayer cache d'abord
  let stats = await redis.get(cacheKey);
  
  if (!stats) {
    // Pas en cache, calculer
    stats = await calculateStatistiques();
    
    // Mettre en cache 1h
    await redis.setex(cacheKey, 3600, JSON.stringify(stats));
  } else {
    stats = JSON.parse(stats);
  }
  
  renderStatistiques(stats);
}

async function calculateStatistiques() {
  // RequÃªtes lourdes Supabase...
  const reservations = await supabase.from('reservations').select('*');
  const ca = reservations.reduce((sum, r) => sum + r.prix, 0);
  const tauxOccupation = calculerTO(reservations);
  
  return { ca, tauxOccupation, nbReservations: reservations.length };
}
```

**Invalider cache quand donnÃ©es changent :**

```javascript
async function ajouterReservation(data) {
  await supabase.from('reservations').insert(data);
  
  // Supprimer cache stats pour forcer recalcul
  await redis.del(`stats:${userId}:${new Date().toISOString().slice(0, 7)}`);
}
```

### âœ… TODO #7 : CDN Cloudflare (1h)

**Pourquoi :** Charger assets (images, CSS, JS) depuis serveurs proches users.

**1. CrÃ©er compte Cloudflare (gratuit)**

**2. Ajouter domaine :**
- DNS > Add site
- Suivre instructions changement nameservers

**3. Activer cache :**
- Page Rules > Create Rule
- `votredomaine.com/images/*` â†’ Cache Level: Cache Everything, TTL: 1 month
- `votredomaine.com/css/*` â†’ Cache Everything, TTL: 1 day
- `votredomaine.com/js/*` â†’ Cache Everything, TTL: 1 day

**4. Versioning assets pour invalider cache :**

```html
<!-- Avant -->
<link rel="stylesheet" href="css/main.css">

<!-- AprÃ¨s (changer version Ã  chaque modif) -->
<link rel="stylesheet" href="css/main.css?v=2.1.0">
```

### âœ… TODO #8 : Monitoring Sentry (2h)

**Pourquoi :** DÃ©tecter erreurs JavaScript avant que users signalent.

**1. Compte Sentry (gratuit 5k events/mois)**

**2. Init dans `index.html` :**

```html
<script src="https://js.sentry-cdn.com/VOTRE_DSN.min.js"></script>
<script>
Sentry.init({
  dsn: "https://xxx@xxx.ingest.sentry.io/xxx",
  environment: "production",
  tracesSampleRate: 0.1, // 10% des requÃªtes
});
</script>
```

**3. Logger erreurs critiques :**

```javascript
try {
  await supabase.from('reservations').insert(data);
} catch (error) {
  Sentry.captureException(error, {
    tags: { section: 'reservations', action: 'create' },
    user: { id: userId }
  });
  alert('Erreur lors de l\'ajout. L\'Ã©quipe technique est notifiÃ©e.');
}
```

### âœ… TODO #9 : Compression images (1h)

**Toutes les images > 500 KB :**

```bash
# Installer ImageMagick
apt-get install imagemagick  # Ubuntu/Debian

# Compresser images
find images/ -name "*.jpg" -exec mogrify -quality 85 -resize 1920x1080\> {} \;
find images/ -name "*.png" -exec mogrify -quality 85 -resize 1920x1080\> {} \;
```

**Ou utiliser service en ligne :** TinyPNG, Squoosh.app

### âœ… TODO #10 : Lazy loading images (30min)

```html
<!-- Avant -->
<img src="images/gite1.jpg" alt="GÃ®te 1">

<!-- AprÃ¨s -->
<img src="images/gite1.jpg" alt="GÃ®te 1" loading="lazy">
```

---

## ðŸŸ£ PALIER 4 : 10 000-30 000 USERS

### Seuil d'action
- > 10M API req/mois **OU**
- Sync iCal prend > 30s **OU**
- Database CPU > 70% (visible dans Supabase Dashboard)

### âœ… TODO #11 : Queue Redis pour syncs iCal (4h)

**Pourquoi :** Ã‰viter que sync iCal bloque interface.

**Installer BullMQ :**

```bash
npm install bullmq
```

**CrÃ©er `js/syncQueue.js` :**

```javascript
import { Queue, Worker } from 'bullmq';

const connection = {
  host: 'UPSTASH_REDIS_HOST',
  port: 6379,
  password: 'UPSTASH_REDIS_PASSWORD'
};

// Queue pour jobs
export const syncQueue = new Queue('ical-sync', { connection });

// Worker qui traite jobs en arriÃ¨re-plan
const worker = new Worker('ical-sync', async (job) => {
  const { userId, giteId, icalUrl } = job.data;
  
  console.log(`[Worker] Sync iCal gÃ®te ${giteId}...`);
  
  // Fetch iCal
  const response = await fetch(icalUrl);
  const icalData = await response.text();
  
  // Parser + insÃ©rer rÃ©servations
  const reservations = parseIcal(icalData);
  await insertReservations(userId, giteId, reservations);
  
  console.log(`[Worker] Sync OK : ${reservations.length} rÃ©servations`);
}, { connection });
```

**Utiliser dans sync :**

```javascript
// AVANT (bloquant)
async function syncAllGites() {
  for (const gite of gites) {
    await syncIcalBlocking(gite.ical_url); // Attend 5-10s par gÃ®te
  }
  alert('Sync terminÃ©e !');
}

// APRÃˆS (non-bloquant)
async function syncAllGites() {
  for (const gite of gites) {
    // Ajouter job Ã  la queue (retour immÃ©diat)
    await syncQueue.add('sync', {
      userId,
      giteId: gite.id,
      icalUrl: gite.ical_url
    }, {
      attempts: 3, // Retry 3x si Ã©chec
      backoff: { type: 'exponential', delay: 2000 }
    });
  }
  alert('Sync lancÃ©e en arriÃ¨re-plan. RafraÃ®chir dans 1 min.');
}
```

### âœ… TODO #12 : Connection pooling Supabase (1h)

**Quand :** Database connections > 80 (visible Dashboard).

Dans Supabase Dashboard :
- Settings > Database
- Connection Pooling : **Activer**
- Mode : **Transaction**
- Pool size : **15** (par dÃ©faut OK)

**Utiliser pooler dans code :**

```javascript
// AVANT (connexion directe)
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

// APRÃˆS (via pooler pour meilleures perfs)
const POOLER_URL = SUPABASE_URL.replace('.supabase.co', '.pooler.supabase.co');
const supabase = createClient(POOLER_URL, SUPABASE_ANON_KEY);
```

### âœ… TODO #13 : Database partitioning (3h)

**Si :** Table `reservations` > 1M rows.

**Partitionner par annÃ©e :**

```sql
-- Transformer table en partitioned table
ALTER TABLE reservations RENAME TO reservations_old;

CREATE TABLE reservations (
  LIKE reservations_old INCLUDING ALL
) PARTITION BY RANGE (date_debut);

-- CrÃ©er partitions par annÃ©e
CREATE TABLE reservations_2024 PARTITION OF reservations
  FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
  
CREATE TABLE reservations_2025 PARTITION OF reservations
  FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
  
CREATE TABLE reservations_2026 PARTITION OF reservations
  FOR VALUES FROM ('2026-01-01') TO ('2027-01-01');

-- Copier donnÃ©es
INSERT INTO reservations SELECT * FROM reservations_old;

-- Supprimer ancienne table
DROP TABLE reservations_old;
```

**RÃ©sultat :** RequÃªtes sur 2026 n'accÃ¨dent QUE Ã  partition 2026 â†’ 3-5x plus rapide.

### âœ… TODO #14 : Vacuum & Analyze automatique (30min)

**PostgreSQL garde anciennes rows = BDD gonfle.**

Activer autovacuum dans Supabase SQL Editor :

```sql
-- VÃ©rifier config actuelle
SHOW autovacuum;

-- Si OFF, activer
ALTER SYSTEM SET autovacuum = on;
SELECT pg_reload_conf();

-- Forcer VACUUM manuel si BDD > 10 GB
VACUUM ANALYZE reservations;
VACUUM ANALYZE users;
VACUUM ANALYZE gites;
```

---

## ðŸ”µ PALIER 5 : 30 000-100 000 USERS

### Seuil d'action
- Database CPU > 80% constant **OU**
- Temps rÃ©ponse > 2s mÃªme avec cache **OU**
- Supabase recommande Enterprise

### âœ… TODO #15 : Migration Supabase Enterprise (30min)

**CoÃ»t :** ~3-5k â‚¬/mois (nÃ©gociable avec Supabase)  
**Avantages :**
- Database replicas (lecture/Ã©criture sÃ©parÃ©es)
- Support prioritaire
- Custom limits

Contact : enterprise@supabase.io

### âœ… TODO #16 : Read replicas (4h setup Supabase)

**Principe :** SÃ©parer lecture/Ã©criture.

- **Ã‰criture (INSERT/UPDATE/DELETE)** â†’ Database principale
- **Lecture (SELECT)** â†’ Replicas (copies en lecture seule)

**Config automatique par Supabase Enterprise.**

**Dans code, utiliser replica pour lectures :**

```javascript
// Connexion principale (Ã©criture)
const supabaseWrite = createClient(SUPABASE_URL, SUPABASE_KEY);

// Connexion replica (lecture)
const REPLICA_URL = 'FOURNI_PAR_SUPABASE_ENTERPRISE';
const supabaseRead = createClient(REPLICA_URL, SUPABASE_KEY);

// LIRE depuis replica
const { data: reservations } = await supabaseRead
  .from('reservations')
  .select('*');

// Ã‰CRIRE sur principale
await supabaseWrite
  .from('reservations')
  .insert(newReservation);
```

### âœ… TODO #17 : Monitoring Datadog (2h)

**Pourquoi :** Surveiller mÃ©triques temps rÃ©el.

**1. Compte Datadog (14j trial puis ~150â‚¬/mois)**

**2. IntÃ©grer :**

```html
<script>
(function(h,o,u,n,d) {
   h=h[d]=h[d]||{q:[],onReady:function(c){h.q.push(c)}} 
   d=o.createElement(u);d.async=1;d.src=n
   n=o.getElementsByTagName(u)[0];n.parentNode.insertBefore(d,n)
})(window,document,'script','https://www.datadoghq-browser-agent.com/datadog-rum.js','DD_RUM')
DD_RUM.onReady(function() {
  DD_RUM.init({
    clientToken: 'VOTRE_TOKEN',
    applicationId: 'VOTRE_APP_ID',
    site: 'datadoghq.eu',
    service: 'liveownerunit',
    env: 'production',
    sessionSampleRate: 100,
    sessionReplaySampleRate: 20,
    trackUserInteractions: true,
    trackResources: true,
    trackLongTasks: true
  });
})
</script>
```

**3. Alertes :**

- Temps rÃ©ponse API > 3s â†’ Email
- Taux erreur > 1% â†’ Email + SMS
- CPU Database > 90% â†’ Alerte critique

### âœ… TODO #18 : Load testing k6 (2h)

**Tester AVANT d'avoir 100k users.**

**Installer k6 :**

```bash
brew install k6  # macOS
# ou
sudo apt-get install k6  # Ubuntu
```

**CrÃ©er test `load-test.js` :**

```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 },    // MontÃ©e 100 users
    { duration: '5m', target: 1000 },   // MontÃ©e 1000 users
    { duration: '10m', target: 10000 }, // Peak 10k users
    { duration: '3m', target: 0 },      // Descente
  ],
  thresholds: {
    http_req_duration: ['p(95)<2000'], // 95% requÃªtes < 2s
    http_req_failed: ['rate<0.01'],     // < 1% erreurs
  },
};

export default function () {
  // Simuler chargement page rÃ©servations
  const res = http.get('https://votredomaine.com/api/reservations', {
    headers: { 
      'Authorization': `Bearer ${__ENV.SUPABASE_TOKEN}` 
    }
  });
  
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 2s': (r) => r.timings.duration < 2000,
  });
  
  sleep(1);
}
```

**Lancer :**

```bash
k6 run load-test.js
```

**RÃ©sultats attendus avec architecture optimisÃ©e :**
- âœ… 10k users simultanÃ©s OK
- âœ… Temps rÃ©ponse p95 < 2s
- âœ… Taux d'erreur < 0.1%

---

## ðŸŽ¯ RÃ‰SUMÃ‰ CHECKLIST COMPLÃˆTE

| Palier | Users | Temps | Actions |
|--------|-------|-------|---------|
| **0** | 0-50 | 0h | Rien (infra Free OK) |
| **1** | 50-500 | 30min | Indexes SQL |
| **2** | 500-2k | 3h | Supabase Pro + Pagination + Optimisations |
| **3** | 2-10k | 8h | Team + Redis + CDN + Monitoring |
| **4** | 10-30k | 10h | Queue + Pooling + Partitioning |
| **5** | 30-100k | 8h | Enterprise + Replicas + Datadog |

**Total : ~30h Ã©talÃ©es sur croissance**

---

## ðŸ’¡ RECOMMANDATIONS FINALES

### Si 100k users atteints

**Vous POUVEZ rester sur cette architecture.** Mais Ã  ce stade :

1. **Embaucher 1-2 DevOps** pour surveiller 24/7
2. **Audit sÃ©curitÃ©** annuel (pentest)
3. **Backup multi-rÃ©gion** (disaster recovery)
4. **SLA 99.9%** avec alerting avancÃ©

### Ã‰volutions optionnelles (NON obligatoires)

Si vraiment besoin aprÃ¨s 100k users :

- **Multi-rÃ©gion Supabase** (edge functions)
- **GraphQL** au lieu de REST (moins de requÃªtes)
- **Microservices** UNIQUEMENT pour services mÃ©tiers lourds (ex: gÃ©nÃ©ration PDF fiches clients)

**Mais PostgreSQL monolithique tient facilement 100k-500k users.**

### CoÃ»ts rÃ©capitulatifs

| Users | Infra/mois | Monitoring/mois | Total/mois | Total/an |
|-------|------------|-----------------|------------|----------|
| 0-500 | 0 â‚¬ | 0 â‚¬ | 0 â‚¬ | 0 â‚¬ |
| 500-2k | 25 â‚¬ | 0 â‚¬ | 25 â‚¬ | 300 â‚¬ |
| 2k-10k | 699 â‚¬ | 150 â‚¬ | 850 â‚¬ | 10k â‚¬ |
| 10k-30k | 699 â‚¬ | 200 â‚¬ | 900 â‚¬ | 11k â‚¬ |
| 30k-100k | 5000 â‚¬ | 300 â‚¬ | 5300 â‚¬ | 64k â‚¬ |

**Total sur 3 ans si croissance jusqu'Ã  100k users : ~150-200kâ‚¬**

ComparÃ© au CA potentiel (100k users Ã— 30â‚¬/mois = 3Mâ‚¬/mois), c'est **nÃ©gligeable**.

---

## ðŸš€ PROCHAINES Ã‰TAPES IMMÃ‰DIATES

**Pour l'instant (0 users) :**

1. â˜ Finir features site
2. â˜ Lancer acquisition premiers clients
3. â˜ **NE PAS optimiser prÃ©maturÃ©ment**

**Ã€ 50 users :**

1. â˜ CrÃ©er indexes SQL (TODO #1)
2. â˜ Setup monitoring basique

**Ã€ 500 users :**

1. â˜ Migrer Supabase Pro
2. â˜ ImplÃ©menter pagination

**Le reste vient naturellement avec la croissance** ðŸš€

---

**FIN DU GUIDE TECHNIQUE**
